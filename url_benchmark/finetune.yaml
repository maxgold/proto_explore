defaults:
  - agent: ddpg
  - override hydra/launcher: submitit_slurm

# mode
reward_free: false
# task settings
domain: point_mass_maze
task: point_mass_maze_custom_goal
task_no_goal: point_mass_maze_reach_no_goal
obs_type: states # [states, pixels]
frame_stack: 3 # only works if obs_type=pixels
action_repeat: 2 # set to 2 for pixels
discount: 0.99
# train settings
num_train_frames: 2000010
num_seed_frames: 4000
# eval
eval_every_frames: 10000
num_eval_episodes: 10
# pretrained
snapshot_ts: 0
snapshot_base_dir: ./pretrained_models
# replay buffer
replay_buffer_size: 1000000
replay_buffer_num_workers: 16
nstep: ${agent.nstep}
test: false #for plotting detailed plots in proto_encoder1
update_encoder: false # can be either true or false depending if we want to fine-tune encoder
# misc
seed: 1
device: cuda
save_video: true
save_train_video: false
use_tb: false
use_wandb: false
goal: false
hybrid: false
hybrid_gc: false
hybrid_pct: .5 #0-1
batch_size: 1024
batch_size_gc: 1024
hidden_dim: 1024
update_gc: 2
replay_buffer_gc: 100000
lr: .0001
goal_index: 0
model_path: None
cassio: False
greene: False
reward_cutoff: 0 # 0 if using env reward
stddev_schedule: .2
stddev_schedule2: .2
stddev_clip: .3
stddev_clip2: .3
episode_length: 500
num_protos: 512
pred_dim: 128
proj_dim: 512
feature_dim: 50
num_iterations: 3
tau: .1
sl: False
asym: False
goal_num: 20
update_proto_every: 2
loss: False
debug: False
lagr: .2
lagr1: .2
lagr2: .2
lagr3: .2
margin: .005
og: True
proto_goal_med: True
proto_goal_mean: False
proto_goal_min: False
combine_storage_gc: False
goal_freq: False
eval_sigma: 1
eval_topk: 5
proto_goal_med_topk: False
proto_goal_mean_topk: False
proto_goal_min_topk: False
proto_goal_mix: False
mix: .5
proto_goal_intr: False
proto_goal_random: False
gc_reached_goals: False
loss_gc: False
update_enc_proto: False
update_enc_gc: False
ot_reward: False
neg_euclid: False
actionable: False
neg_euclid_state: True
nstep1: 3
nstep2: 3
tmux_session: ???
test1: False
offline: False
pmm_reward_cutoff: 10
# experiment
experiment: exp


hydra:
  run:
    dir: ./exp_local/${now:%Y.%m.%d}/${now:%H%M%S}_${agent.name}
  sweep:
    dir: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}
    subdir: ${hydra.job.num}
  launcher:
    timeout_min: 4300
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 160
    nodes: 1
    submitit_folder: ./exp_sweep/${now:%Y.%m.%d}/${now:%H%M}_${agent.name}_${experiment}/.slurm
